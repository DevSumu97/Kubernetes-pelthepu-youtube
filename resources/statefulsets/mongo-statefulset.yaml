apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mongo
spec:
  selector:
    matchLabels:
      app: mongo
  serviceName: "mongo"
  replicas: 3
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: mongo:4.0.8
          startupProbe:          #startupProbe is used to check if your application has started successfully before Kubernetes begins performing liveness or readiness checks.
            exec:                # Runs a command inside the container — here it runs the Mongo shell and executes db.adminCommand('ping')
              command:           # which checks if MongoDB is ready to accept connections.
                - mongo
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 1      # Wait 1 second after container starts before first probe.
            periodSeconds: 10           # Run the probe every 10 seconds. (Frequency)
            timeoutSeconds: 5           # timeoutSeconds specifies how long Kubernetes should wait for a probe to respond before it decides that the probe failed.
            successThreshold: 1         # successThreshold defines how many consecutive successful probe results Kubernetes needs before considering the container healthy.
            failureThreshold: 2        # failureThreshold defines how many consecutive probe failures must occur before Kubernetes considers the container unhealthy
          livenessProbe:               # livenessProbe tells K8S whether your container is still running properly or not
            exec:                      #If the liveness probe fails K8s restarts the container inside the same Pod (without deleting the Pod).
              command:                 # Sometimes a container’s process: Doesn’t crash, But gets stuck (e.g., deadlock, infinite loop, full memory).
                - mongo                # Kubernetes can’t detect that automatically.So the liveness probe will detect and it fails So that the container will get restarted.
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 2
          readinessProbe:          # A readinessProbe checks whether a container is ready to serve traffic. 
            exec:                  # If it fails, the Pod is marked as NotReady, and Kubernetes removes it from Service endpoints. Unlike livenessProbe, it does not restart the container.
              command:
                - mongo
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 2
          env:
            - name: MONGO_INITDB_ROOT_USERNAME  # This is the environment variable provided in the pod.yaml which over rides the env variable given in the configmap (username) 
              valueFrom:
                configMapKeyRef:
                  key: username
                  name: mongodb-config          # Name of the configmap
            - name: MONGO_INITDB_ROOT_PASSWORD # This is the environment variable provided in the pod.yaml which over rides the env variable given in the secret (password)
              valueFrom:
                secretKeyRef:
                  key: password               # password is the key defined in the secret 
                  name: mongodb-secret        # Name of the Secret    
          command:                      # The command: field overrides the default ENTRYPOINT from the Docker image.
            - mongod                    # The main MongoDB server process (daemon).
            - "--bind_ip_all"           # Tells MongoDB to accept connections from any network interface, not just localhost. This is critical inside Kubernetes, where pods communicate over the cluster network.
            - --config=/etc/mongo/mongod.conf  # Instructs MongoDB to read settings (like dbPath, replication, etc.) from the given config file — which in your case comes from the ConfigMap mounted at /etc/mongo/mongod.con
          volumeMounts:                  # volumeMounts: define where the container sees the volumes inside its filesystem.
            - name: mongo-volume         #  mongo-volume → mounted at /data/db → this is where MongoDB stores its data files (the database itself).Typically, this points to a PersistentVolumeClaim (PVC).
              mountPath: /data/db        # The database files get stored persistently in /data/db, backed by mongo-volume.
            - name: mongodb-config       # mongodb-config → mounted at /etc/mongo → this is where MongoDB expects its configuration file (mongod.conf).
              mountPath: /etc/mongo
      volumes:                           #volumes define what each volume actually is (source).
        - name: mongodb-config           #The mongodb-config volume is populated from a ConfigMap called mongodb-config
          configMap:
            name: mongodb-config         #Inside that ConfigMap, there’s a key mongodb.conf which is written to the file /etc/mongo/mongodb.conf inside the container
            items:                       # The items: section lets you control which keys to be mounted from configmap which consists lot of keys, and optionally rename them by using a option "path".
              - key: mongodb.conf        # key: → which key in the ConfigMap to use
                path: mongod.conf        # path: → what filename to create inside the volume. If path is not mentioned to rename the file, then the name of the file will be same as key name.
                 # Because of path the file inside the container will be named as mongod.conf =>  /etc/mongo/mongod.conf.
                # This is often done because MongoDB expects the file to be named mongod.conf, not mongodb.conf.
          #configMap:                     #Then every key in that ConfigMap becomes a file in the volume (If we mention the name of the configmap directly)
          # name: mongodb-config          # The container would get: (etc/mongo/username→ contains "admin1" & /etc/mongo/mongodb.conf → contains your YAML config)
  volumeClaimTemplates:           # Creates a dedicated Persistant volume for each pod's
    - metadata:
        name: mongo-volume
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: demo-storage
        resources:
          requests:
            storage: 1Gi

===========================================
# mongodb-config.yaml

apiVersion: v1
kind: ConfigMap
metadata:    
  name: mongodb-config     # metadata.name: mongodb-config → name used to reference this ConfigMap in your Deployment or StatefulSet.
immutable: false           # Means the ConfigMap can be updated later. If set to true, you cannot modify its contents after creation (you’d have to delete and recreate it).
data:                      # The data section holds key-value pairs. You have two keys here (username & mongodb.conf)  
  username: admin1
  mongodb.conf: |         # This is your actual MongoDB config file content. The | symbol means “multi-line literal block,” so YAML keeps the formatting.
    storage:
      dbPath: /data/db        # storage.dbPath — where to store database files.
    replication:
        replSetName: "rs0"     # replication.replSetName — the name of your replica set (used when you’re setting up MongoDB replication)

========================================
# mongo-secret.yaml
      
apiVersion: v1
kind: Secret
metadata: 
  name: mongodb-secret
immutable: false
type: Opaque
data:
  password: cGFzc3dvcmQxMjM=  
==============================================
# StorageClass.yaml
  apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: demo-storage
provisioner: k8s.io/minikube-hostpath  ( Minikube will Not work so use the below yaml) 
volumeBindingMode: Immediate
reclaimPolicy: Delete


# StorageClass.yaml

# You can install the Local Path Provisioner (from Rancher) with: 
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml

Step1: 
storageclass.yaml

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: demo-storage
provisioner: rancher.io/local-path
volumeBindingMode: Immediate
reclaimPolicy: Delete

            
